{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Réseau de neurones\n",
    "\n",
    "-- Courtenay Rebecca & Nguyen Duc Anh"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Table des matières\n",
    "\n",
    "* [I. Importation des packages](#chapter1)\n",
    "* [II. Implémentation en code python](#chapter2)\n",
    "    * [1. Modèle de type perceptron multi-couches](#section_2_1)\n",
    "    * [2. Représentations de taux d’erreur et de taux de réussite](#section_2_2)\n",
    "    * [3. Représentations des erreurs](#section_2_3)\n",
    "        * [3.1. Matrice de confusion](#section_2_2_2)\n",
    "        * [3.2. Affichage des erreurs](#section_2_2_3)\n",
    "* [III. Préparation des données](#chapter3)\n",
    "    * [1. Fonctions de pré-traitement](#section_3_1)\n",
    "        * [1.1. Normalisation des données](#section_3_1_1)\n",
    "        * [1.2. Standardisation des données](#section_3_1_2)\n",
    "        * [1.3. Seuillage des images](#section_3_1_3)\n",
    "        * [1.4. Data augmentation](#section_3_1_4)\n",
    "    * [2. Représentation des 25 premières images](#section_3_2)\n",
    "    * [3. Préparation des nouveaux jeux de données](#section_3_3)\n",
    "* [IV. Elaboration des expérimentations](#chapter4)\n",
    "    * [1. Chargement des données du fichier mnist](#section_4_1)\n",
    "    * [2. Sans pré-traitement (sauf normalisation) des données](#section_4_2)\n",
    "        * [2.1. Expérimentation: algorithme optimisation SGD avec différents batch size](#section_4_2_1)\n",
    "        * [2.2. Expérimentation: algorithme optimisation Adam, 2 couches cachées avec différents batch size](#section_4_2_2)\n",
    "        * [2.3. Expérimentation: algorithme optimisation Adam, 3 couches cachées avec différents batch size](#section_4_2_3)\n",
    "    * [3. Data augmentation](#section_4_4)\n",
    "        * [3.1. Expérimentation: algorithme optimisation Adam avec différents batch size](#section_4_4_1)\n",
    "    * [4. Avec seuillage](#section_4_3)\n",
    "        * [4.1. Expérimentation: algorithme optimisation Adam avec différents batch size](#section_4_3_1)\n",
    "    * [5. Avec standardisation des données](#section_5_4)\n",
    "        * [5.1. Expérimentation: algorithme optimisation Adam, 3 couches cachées avec différents batch size](#section_4_5_1)\n",
    "    * [6. Meilleur modèle](#section_6_4)\n",
    "        * [6.1. Comparaison taux de réussite](#section_4_6_1)\n",
    "        * [6.2. Meilleur modèle](#section_4_6_2)\n",
    "            * [6.2.1. Meilleur modèle sans sur-apprentissage](#section_4_6_2_1)\n",
    "* [V. Conclusion](#chapter5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## I. Importation des packages <a class= \"anchor\" id=\"chapter1\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## II. Implémentation en code python <a class= \"anchor\" id=\"chapter2\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Modèle de type perceptron multi-couches <a class= \"anchor\" id=\"section_2_1\"></a>\n",
    "\n",
    "Création de la fonction python permettant de produire différents réseaux de neurones de type perceptron multicouches.\n",
    "\n",
    "Pour la création du modèle, elle se fait couche par couche. Nous avons un modèle de type perceptron multi-couches, où le nombre de couches à faire est à entré en paramètre, avec :\n",
    "- Dropout : fixé à 20% → une entrée sur 5 sera exclue de manière aléatoire dans chaque cycle de mise à jour ;\n",
    "- Des couches cachées de 128 neurones (par défaut mais peut être modifié) avec des activations (ReLU par défaut, mais peut être modifié) ;\n",
    "- Une couche de sortie de 10 neurones avec activation Softmax car en sortie nous avons un label et plusieurs classes.\n",
    "\n",
    "Puis nous avons configuré la méthode d'entrainement de ce modèle en prenant en compte plusieurs critères :\n",
    "- optimizer : algorithme d'optimisation utilisé (par défaut adam mais peut être modifié) ;\n",
    "- loss : la fonction objective que l'on souhaite minimiser (ici sparse_categorical_crossentropy) ;\n",
    "- metrics : la métrique considée pour évaluer les performances (ici accuracy).\n",
    "\n",
    "Puis, nous pouvons entraîner le modèle en précisant la façon dont les données seront présentées lors de l'entrainement :\n",
    "- epochs : un passage sur l'ensemble des données de la base d'entrainement (par défaut 20, mais peut être modifié) ;\n",
    "- batch_size : définit le nombre d'exemples qui seront propagés à chaque itération pour calculer la mise à jour des poids (par défaut 128, mais peut être modifié).\n",
    "\n",
    "Ensuite, nous ajustons le modèle : nous l'entraînons donc sur nos données train. Où :\n",
    "- epochs : nombre de fois qu'il faut itérer sur les tableaux de données ;\n",
    "- batch_size : nombre d'échantillons par mise à jour du gradient ;\n",
    "- callbacks : objet qui peut effectuer des actions à différentes étapes de la formation qui a été crée par nous même avec callbacks.EarlyStopping :\n",
    "    - monitor : quantité à surveiller (ici les pertes \"loss\") ;\n",
    "    - mode : mode (ici \"min\") ;\n",
    "    - patience : nombre d'époch sans amélioration après lesquelles l'entrainement sera arrêté (ici 4) ;\n",
    "    - restore_best_weights : s'il faut tester les poids du modèle à partir de l'époch avec la meilleure valeur de la quantité surveillé (ici vrai) ;\n",
    "    - verbose : mode de verbosité (ici 2 : une ligne de journal par époch) ;\n",
    "    - validation_data : données qui aide à la validation (ici x_validate et y_validate).\n",
    "\n",
    "Pour finir, nous avons cherché à valider notre modèle. En effet, nous regardons si le modèle est le mieux adapté au problème donné et aux données correspondantes. Pour cela, nous avons besoin des données de test et leurs étiquettes. Nous rentrons également le nombre d'exemples à propagés pour chaque itération."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mlp_model(train_set, test_set, validate_set, optimizer_name='adam',\n",
    "              nb_hidden_layer=3, nb_cellules=128, batch_size=128,\n",
    "              learning_rate=0.001, epochs=20, activation_function=\"relu\", do_data_augmentation=False):\n",
    "    \"\"\"\n",
    "    :param do_data_augmentation : algorithm de data augmentation\n",
    "    :param optimizer_name : algorithme d'optimisation utilisé (par défaut adam mais peut être modifié)\n",
    "    :param batch_size : nombre d'échantillons par mise à jour du gradient\n",
    "    :param train_set :\n",
    "    :param test_set :\n",
    "    :param validate_set :\n",
    "    :param learning_rate :\n",
    "    :param activation_function : type de fonction d'activation\n",
    "    :param epochs : nombre de fois qu'il faut itérer sur les tableaux de données\n",
    "    :param nb_hidden_layer : nombre de couches cachées\n",
    "    :param nb_cellules : nombre de cellules par couche cachée\n",
    "    \"\"\"\n",
    "\n",
    "    keras_model = keras.models.Sequential()\n",
    "    keras_model.add(Dropout(0.2))\n",
    "    for ix in range(nb_hidden_layer):\n",
    "        keras_model.add(Dense(nb_cellules, activation=activation_function))\n",
    "    # une couche de sortie de 10 neurones avec activation Softmax\n",
    "    keras_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    x_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    x_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "    x_validate = validate_set[0]\n",
    "    y_validate = validate_set[1]\n",
    "\n",
    "    #Compilation\n",
    "    optimizer = None\n",
    "    if optimizer_name == \"sgd\":\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    elif optimizer_name == \"adam\":\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    keras_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    callback = [keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=4, restore_best_weights=True)]\n",
    "\n",
    "    #Fit\n",
    "    if do_data_augmentation:\n",
    "        train_gen, validate_gen = data_augmentation(x_train, y_train, x_validate, y_validate)\n",
    "        keras_model_fit = keras_model.fit(train_gen.x.reshape(len(train_gen.x), 784), train_gen.y, epochs=epochs, batch_size=batch_size, callbacks=callback, verbose=0, validation_data=(validate_gen.x.reshape(len(validate_gen.x), 784), validate_gen.y))\n",
    "    else:\n",
    "        keras_model_fit = keras_model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=callback, verbose=0, validation_data=(x_validate, y_validate))\n",
    "\n",
    "    #Summary\n",
    "    #     model.summary()\n",
    "\n",
    "    #Evaluate\n",
    "    model_score = keras_model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "\n",
    "    return keras_model, keras_model_fit, model_score\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ensuite, nous enregistrons tous les modèles que nous avons effectué dans model_path."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_model(my_model, my_model_name):\n",
    "    save_dir = \"./results/\"\n",
    "    model_path = save_dir + my_model_name\n",
    "    my_model.save(model_path)\n",
    "    print('Saved trained model at %s ' % model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Représentations de taux d'erreur et taux de réussite <a class= \"anchor\" id=\"section_2_2\"></a>\n",
    "\n",
    "Grâce à l'historique de model.fit (voir Implémentation en code Python) nous pouvons récupérer plusieurs métriques qui sont stockées dans un dictionnaire :\n",
    "- accuracy\n",
    "- val_accuracy\n",
    "- loss\n",
    "- val_loss\n",
    "\n",
    "De ce fait, cela inclut la perte (loss) et la précision (accuracy) ainsi que la perte et la précision de l'ensemble de données de validation. Et nous pouvons créer des graphiques à partir de celles-ci.\n",
    "\n",
    "Nous avons créé un graphique de précision (accuracy) sur les ensembles de données d'entrainement et de validation.\n",
    "\n",
    "Puis un graphique de perte (loss) sur les ensembles de données d'entrainement et de validation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_model_result(target_model_fit):\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(target_model_fit.history['accuracy'])\n",
    "    plt.plot(target_model_fit.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='lower right')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(target_model_fit.history['loss'])\n",
    "    plt.plot(target_model_fit.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Représentations des erreurs <a class= \"anchor\" id=\"section_2_3\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1. Matrice de confusion <a class= \"anchor\" id=\"section_2_2_2\"></a>\n",
    "\n",
    "Nous mettons en place une matrice de confusion permettant de nous donner la différence entre la prédiction et la valeur que représente l'image.\n",
    "\n",
    "Chaque ligne de la matrice représente les instances de la véritable classe alors que chaque colonne représente les instances de la classe de prédiction.\n",
    "\n",
    "Pour cela, nous récupérons d'abord le modèle prédictif ajusté grâce aux jeux de données test.\n",
    "\n",
    "Puis nous appliquons la fonction argmax de numpy qui renvoie l'index de l'axe le plus grand. Par exemple, ici, nous avons d'abord y_pred = [0 1 0 0 0 0 0 0 0], cela représente le 1. Avec argmax, Y_pred deviendra donc 1. Nous faisons cela pour les véritables valeurs et les prédictions.\n",
    "\n",
    "Ensuite, nous appliquons la fonction confusion_matrix qui évalue l'exactitude d'une classification.\n",
    "Pour son affichage, nous prenons sa transposé pour tracer les données sous forme de matrice codée en couleur (nuance de bleu ici) avec des rectangles."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model_to_plot, test_data):\n",
    "    y_pred = model_to_plot.predict(test_data[0])\n",
    "    y_pred_label = np.argmax(y_pred, 1)\n",
    "    y_test_label = list(test_data[1])\n",
    "\n",
    "    mat = confusion_matrix(y_test_label, y_pred_label)\n",
    "    cmd = ConfusionMatrixDisplay(confusion_matrix=mat.T)\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 8))\n",
    "    cmd.plot(cmap=plt.cm.Blues, ax=ax1)\n",
    "\n",
    "    return y_pred_label, y_test_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2. Affichage des erreurs <a class= \"anchor\" id=\"section_2_2_3\"></a>\n",
    "Afficher des images que le modèle prédit incorrectement.\n",
    "\n",
    "Pour cela, nous récupèrons les index dans prédiction et dans le jeu de données test, où il y a une erreur entre la prédiction et la véritable valeur.\n",
    "\n",
    "Ainsi, nous affichons, une fois pour les 10 chiffres, l'image de la vraie valeur et sa prédiction.\n",
    "Pour cela, notre if vérifie bien que nous prenons une fois le même chiffre en s'aidant de son emplacement et qu'il y a bien des erreurs de prédictions (si ce n'est pas le cas, aucune erreur ne s'affiche)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def display_errors(label_pred, label_test, data_test):\n",
    "    #     label_test = np.argmax(label_test, 1)\n",
    "    label_test = label_test.values\n",
    "    errors = (label_pred - label_test != 0)\n",
    "    Y_pred_errors_class = label_pred[errors]  # [1, 2, 3, 5, 9, ....]\n",
    "    Y_test_errors_class = label_test[errors]  # [2, 2, 3, 5, 9, ....]\n",
    "\n",
    "    X_test_errors = data_test[errors]\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 5\n",
    "    fig, ax3 = plt.subplots(nrows, ncols, figsize=(10, 7))\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error_index = np.where(Y_test_errors_class == ncols * row + col)\n",
    "            if error_index and len(error_index[0]) != 0:\n",
    "                error_index = np.random.choice(error_index[0], size=1)\n",
    "            else:\n",
    "                continue\n",
    "            ax3[row, col].imshow((X_test_errors[error_index]).reshape((28, 28)), cmap=plt.cm.binary)\n",
    "            ax3[row, col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(Y_pred_errors_class[error_index], Y_test_errors_class[error_index]))\n",
    "            n += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## III. Préparation des données <a class= \"anchor\" id=\"chapter3\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Fonctions de pré-traitement <a class= \"anchor\" id=\"section_3_1\"></a>\n",
    "Nous effectuons des pré-traitements sur les données d'entrée à travers différentes fonctions :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1. Normalisation des données <a class= \"anchor\" id=\"section_3_1_1\"></a>\n",
    "Normaliser les données pour avoir des données entre 1 et -1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return x / 255"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2. Standardisation des données <a class= \"anchor\" id=\"section_3_1_2\"></a>\n",
    "Standardiser les données en supprimant la moyenne et en mettant à l'échelle la variance unitaire."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    mean_px = x.mean().astype(np.float32)\n",
    "    std_px = x.std().astype(np.float32)\n",
    "    x_scaled = (x - mean_px) / std_px\n",
    "    return x_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.3. Seuillage des images <a class= \"anchor\" id=\"section_3_1_3\"></a>\n",
    "\n",
    "Appliquer un seuillage manuelle sur une image en prenant compte de plusieurs paramètres :\n",
    "- image à traiter ;\n",
    "- valeur du seuil (0.5 par défaut) ;\n",
    "- la couleur que prendra les objets une fois seuillé (ici 1) ;\n",
    "- type de seuillage (ici TRESH_BINARY)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def img_preprocessing(x, threshold=0.5):\n",
    "    # return cv.threshold(x, threshold, 1, cv.THRESH_BINARY)[1]\n",
    "    return np.where(x >= threshold, 1.0, 0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.4. Data augmentation <a class= \"anchor\" id=\"section_3_1_4\"></a>\n",
    "\n",
    "Pivoter aléatoirement nos images :\n",
    "- featurewise_center : définit la moyenne d'entrée sur 0 sur l'ensemble de données (ici non) ;\n",
    "- samplewise_center : définit chaque moyenne d'échantillon sur 0 (ici non) ;\n",
    "- featurewise_std_normalization : diviser les entrées par l'écart-type de l'ensemble de données (ici non) ;\n",
    "- samplewise_std_normalization : diviser chaque entrée par sa norme (ici non) ;\n",
    "- zca_whitening : appliquer le ZCA de Blanchinement (ici non) ;\n",
    "- rotation_range : faire pivoter aléatoirement les images dans la plage (de 0° à 180°) (ici à 15°) ;\n",
    "- zoom_range : agrandir l'image au hasard (ici de 0.01) ;\n",
    "- width_shift_range : décaler aléatoirement les images horizontalement (ici de 0.1 (fraction de la largeur totale)) ;\n",
    "- height_shift_range : décaler aléatoirement les images verticalement (ici de 0.1 (fraction de la largeur totale)) ;\n",
    "- horizontal_flip : images retournées au hasard à l'horizontale (ici non) ;\n",
    "- vertical_flip : images retournées au hasard à la verticale (ici non)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def data_augmentation(x_train, y_train, x_validate, y_validate):\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=15,\n",
    "        zoom_range=0.01,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False)\n",
    "\n",
    "    train_gen = datagen.flow(x_train.reshape(len(x_train), 28, 28, 1), y_train, batch_size=128)\n",
    "    validate_gen = datagen.flow(x_validate.reshape(len(x_validate), 28, 28, 1), y_validate, batch_size=128)\n",
    "    return train_gen, validate_gen"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Représentation des 25 premières images <a class= \"anchor\" id=\"section_3_2\"></a>\n",
    "\n",
    "- prépration du jeu de données pour qu'il soit conforme : donne une nouvelle \"shape\" ;\n",
    "- plt.subplot : création d'une figure avec 5x5 grilles de sous-parcelles ;\n",
    "- plt.xticks : définir les emplacements des graduations de l'axe x ;\n",
    "- plt.yticks : définir les emplacements des graduations de l'axe y ;\n",
    "- plt.grid : si on veut afficher les grilles (ici non) ;\n",
    "- plt.imshow : afficher les données sous forme d'image (2D)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def display_img(x, y):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    x = x.reshape(len(x), 28, 28, 1)\n",
    "    for ixx in range(25):\n",
    "        plt.subplot(5, 5, ixx + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(x[ixx], cmap=plt.cm.binary)\n",
    "        plt.title(y[ixx])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Préparation des nouveaux jeux de données <a class= \"anchor\" id=\"section_3_3\"></a>\n",
    "\n",
    "Appel du jeu de données mnist_all et création des jeux test, train et validate\n",
    "- Partager données entre Y et X :\n",
    "    - Y : les données de la première colonne du jeu de données -> elles représentent les numéros qu'il faut avoir ;\n",
    "    - X : les données -> pixels des images.\n",
    "- train_test_split : divise nos jeux de données en sous-ensembles d'entraînement, de test et de validation\n",
    "    - test_size : donner la proportion que nous voulons mettre dans d'abord test puis dans validate : 10% dans test, 20% dans validate et 70% dans train ;\n",
    "    - stratify : divise l'ensemble de données en conservant les mêmes proportions d'exemples dans chaque classe que celles observées dans l'ensemble de données d'origine ;\n",
    "    - On l'applique 2 fois pour séparer en 3 fois les jeux de données initiaux.\n",
    "- plot : permettre l'affichage des chiffres (y) en général puis dans chaque jeux de données."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_and_split_data():\n",
    "    data = pd.read_csv(\"mnist_all.csv\")\n",
    "    x = np.array(data.iloc[:, 1:])\n",
    "    y = data.iloc[:, 0]\n",
    "\n",
    "    x_train_validate, x_test, y_train_validate, y_test = train_test_split(x, y, test_size=0.1, random_state=0, stratify=y)\n",
    "    x_train, x_validate, y_train, y_validate = train_test_split(x_train_validate, y_train_validate, test_size=0.2, random_state=0, stratify=y_train_validate)\n",
    "\n",
    "    #plot for distribution sort descending\n",
    "    all_label = y.value_counts().sort_index(ascending=False).plot(kind='barh', title=\"Label distribution\")\n",
    "    all_label.bar_label(all_label.containers[0])\n",
    "\n",
    "    #plot label for train, test , validate\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "    train_label_plot = y_train.value_counts().sort_index(ascending=False).plot(kind='barh', ax=axes[0], title=\"Train label distribution - 70%\")\n",
    "    train_label_plot.bar_label(train_label_plot.containers[0])\n",
    "    test_label_plot = y_test.value_counts().sort_index(ascending=False).plot(kind='barh', ax=axes[1], title=\"Test label distribution - 10%\")\n",
    "    test_label_plot.bar_label(test_label_plot.containers[0])\n",
    "    validate_label_plot = y_validate.value_counts().sort_index(ascending=False).plot(kind='barh', ax=axes[2], title=\"Validation label distribution - 20%\")\n",
    "    validate_label_plot.bar_label(validate_label_plot.containers[0])\n",
    "\n",
    "    return [x_train, y_train], [x_test, y_test], [x_validate, y_validate]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Préparation final du jeu de donnée et affichage de la distribution des classes dans chaque ensemble de données.\n",
    "- Normalisation de nos x (train, test, validate) ;\n",
    "- Standardisation de nos x (optionnel) ;\n",
    "- Appliquation d'un seuil sur une image (ici sur nos x_train, x_test, x_validate) (optionnel) ;\n",
    "- Affichage des états de nos nouveaux jeux de données."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def data_preparation(train_origin, test_origin, validate_origin, process_img=False, standard_application=False):\n",
    "    x_train = normalize(train_origin[0])\n",
    "    x_test = normalize(test_origin[0])\n",
    "    x_validate = normalize(validate_origin[0])\n",
    "\n",
    "    if standard_application:\n",
    "        x_train = standardize(x_train)\n",
    "        x_test = standardize(x_test)\n",
    "        x_validate = standardize(x_validate)\n",
    "\n",
    "    if process_img:\n",
    "        x_train = img_preprocessing(x_train)\n",
    "        x_test = img_preprocessing(x_test)\n",
    "        x_validate = img_preprocessing(x_validate)\n",
    "\n",
    "    # y_train = keras.utils.to_categorical(train_origin[1], 10)\n",
    "    # y_test = keras.utils.to_categorical(test_origin[1], 10)\n",
    "    # y_validate = keras.utils.to_categorical(validate_origin[1], 10)\n",
    "\n",
    "    y_train = train_origin[1]\n",
    "    y_test = test_origin[1]\n",
    "    y_validate = validate_origin[1]\n",
    "\n",
    "    print('shape X train : ', x_train.shape)\n",
    "    print('shape X test : ', x_test.shape)\n",
    "    print('shape X validate : ', x_validate.shape)\n",
    "    print('shape Y train : ', y_train.shape)\n",
    "    print('shape Y test : ', y_test.shape)\n",
    "    print('shape Y validate : ', y_validate.shape)\n",
    "\n",
    "    return [x_train, y_train], [x_test, y_test], [x_validate, y_validate]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IV. Elaboration des expérimentations <a class= \"anchor\" id=\"chapter4\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Chargement des données du fichier mnist <a class= \"anchor\" id=\"section_4_1\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_org, test_org, validate_org = load_and_split_data()\n",
    "all_scores = {}\n",
    "all_models = {}\n",
    "all_models_fit = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous remarquons qu'il y a une bonne répartition des images pour chaque chiffres."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Sans pré-traitement (sauf normalisation) des données <a class= \"anchor\" id=\"section_4_2\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train, test, validate = data_preparation(train_org, test_org, validate_org, process_img=False, standard_application=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_img(train[0], train[1].values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1. Expérimentation : algorithme optimisation SGD avec différents batch size <a class= \"anchor\" id=\"section_4_2_1\"></a>\n",
    "Description de l'expérimentation :\n",
    "* nombre de couches cachées: **3**\n",
    "* nombre de cellule: **128**\n",
    "* batch size: **[32, 86, 200, 450]**\n",
    "* optimizer: **SGD**\n",
    "* learning rate: **0.001**\n",
    "* epochs: **30**\n",
    "* process image method: **None**\n",
    "* activation function: **relu**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_sizes = [32, 86, 200, 450]\n",
    "plt.figure(figsize=(10, 8)).subplots_adjust(hspace=2, wspace=0.4)\n",
    "for i in range(len(batch_sizes)):\n",
    "    model, model_fit, score = mlp_model(train_set=train,\n",
    "                                        test_set=test,\n",
    "                                        validate_set=validate,\n",
    "                                        optimizer_name=\"sgd\",\n",
    "                                        nb_hidden_layer=3,\n",
    "                                        nb_cellules=128,\n",
    "                                        batch_size=batch_sizes[i],\n",
    "                                        learning_rate=0.001,\n",
    "                                        epochs=30,\n",
    "                                        activation_function=\"relu\")\n",
    "\n",
    "    plot_no = 420 + (i + 1)\n",
    "    plt.subplot(plot_no)\n",
    "    plt.plot(model_fit.history['accuracy'], label='train')\n",
    "    plt.plot(model_fit.history['val_accuracy'], label='validate')\n",
    "    plt.title('batch=' + str(batch_sizes[i]), pad=-40)\n",
    "\n",
    "    all_scores[\"model_sgd_\" + str(batch_sizes[i])] = score\n",
    "    all_models[\"model_sgd_\" + str(batch_sizes[i])] = model\n",
    "    all_models_fit[\"model_sgd_\" + str(batch_sizes[i])] = model_fit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pour ces modèles, nous remarquons qu'il est préférable de prendre un batch petit lorsque nous utilisons comme algortihme d'optimisation SGD qui est l'algorithme du gradient stochastique. En effet le temps d'exécution est plus long et le taux de réussite devient moins important.\n",
    "\n",
    "Cela est sûrement dû au fait que le calcul du gradient stochastique se concentre sur différents échantillons de l'ensemble de données global à chaque itération et donc plus le batch augmente plus le temps de calcul à chaque itération devient coûteux en temps et en ressources.\n",
    "De plus, les grandes tailles de lot ne permettent pas au modèle de voyager assez loin pour atteindre les meilleures soluions pour le même nombre d'époch d'entraînement. D'où le fait qu'il est mieux de prendre un batch size assez petit.\n",
    "\n",
    "Il faudrait augmenter le taux d'apprentissage ou le nombre d'epoch afin que le modèle puisse trouver des meilleures solutions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2. Expérimentation : algorithme optimisation Adam, 2 couches cachées avec différents batch size <a class= \"anchor\" id=\"section_4_2_2\"></a>\n",
    "Description de l'expérimentation :\n",
    "* nombre de couches cachées: **2**\n",
    "* nombre de cellule: **128**\n",
    "* batch size: **[32, 86, 200, 450]**\n",
    "* optimizer: **Adam**\n",
    "* learning rate: **0.001**\n",
    "* epochs: **30**\n",
    "* process image method: **None**\n",
    "* activation function: **relu**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_sizes = [32, 86, 200, 450]\n",
    "plt.figure(figsize=(10, 8)).subplots_adjust(hspace=2, wspace=0.4)\n",
    "\n",
    "for i in range(len(batch_sizes)):\n",
    "    model, model_fit, score = mlp_model(train_set=train,\n",
    "                                        test_set=test,\n",
    "                                        validate_set=validate,\n",
    "                                        optimizer_name=\"adam\",\n",
    "                                        nb_hidden_layer=2,\n",
    "                                        nb_cellules=128,\n",
    "                                        batch_size=batch_sizes[i],\n",
    "                                        learning_rate=0.001,\n",
    "                                        epochs=30,\n",
    "                                        activation_function=\"relu\")\n",
    "    plot_no = 420 + (i + 1)\n",
    "    plt.subplot(plot_no)\n",
    "\n",
    "    plt.plot(model_fit.history['accuracy'], label='train')\n",
    "    plt.plot(model_fit.history['val_accuracy'], label='validate')\n",
    "    plt.title('batch=' + str(batch_sizes[i]), pad=-40)\n",
    "\n",
    "    all_scores[\"model_adam_2couches\" + str(batch_sizes[i])] = score\n",
    "    all_models[\"model_adam_2couches\" + str(batch_sizes[i])] = model\n",
    "    all_models_fit[\"model_adam_2couches\" + str(batch_sizes[i])] = model_fit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ici, nous remarquons que plus le batch augmente, plus le temps d'éxecution augmente ainsi que le taux de réussite.\n",
    "\n",
    "L'algorithme Adam est plus efficace que SGD pour travailler avec beaucoup de données (comme ici). Il prend en considération la moyenne pondérée exponentielle des gradients et a une insensibilité à l'initialisation du poids et au choix du taux initial d'apprentissage. Il trouve donc des solutions avec des poids beaucoup plus importants."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3. Expérimentation : algorithme optimisation Adam, 3 couches cachées avec différents batch size <a class= \"anchor\" id=\"section_4_2_3\"></a>\n",
    "Description de l'expérimentation :\n",
    "* nombre de couches cachées: **3**\n",
    "* nombre de cellule: **128**\n",
    "* batch size: **[32, 86, 200, 450]**\n",
    "* optimizer: **Adam**\n",
    "* learning rate: **0.001**\n",
    "* epochs: **30**\n",
    "* process image method: **None**\n",
    "* activation function: **relu**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_sizes = [32, 86, 200, 450]\n",
    "plt.figure(figsize=(10, 8)).subplots_adjust(hspace=2, wspace=0.4)\n",
    "\n",
    "for i in range(len(batch_sizes)):\n",
    "    model, model_fit, score = mlp_model(train_set=train,\n",
    "                                        test_set=test,\n",
    "                                        validate_set=validate,\n",
    "                                        optimizer_name=\"adam\",\n",
    "                                        nb_hidden_layer=3,\n",
    "                                        nb_cellules=128,\n",
    "                                        batch_size=batch_sizes[i],\n",
    "                                        learning_rate=0.001,\n",
    "                                        epochs=30,\n",
    "                                        activation_function=\"relu\")\n",
    "    plot_no = 420 + (i + 1)\n",
    "    plt.subplot(plot_no)\n",
    "\n",
    "    plt.plot(model_fit.history['accuracy'], label='train')\n",
    "    plt.plot(model_fit.history['val_accuracy'], label='validate')\n",
    "    plt.title('batch=' + str(batch_sizes[i]), pad=-40)\n",
    "\n",
    "    all_scores[\"model_adam_3couches\" + str(batch_sizes[i])] = score\n",
    "    all_models[\"model_adam_3couches\" + str(batch_sizes[i])] = model\n",
    "    all_models_fit[\"model_adam_3couches\" + str(batch_sizes[i])] = model_fit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comparées aux expérimentations faites juste au-dessus, nous ne remarquons pas une grande différence. En effet, le nombre de couches cachées (ici 3 e 2 plus haut) n'a pas d'impact important sur le choix de notre modèle."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Data augmentation <a class= \"anchor\" id=\"section_4_4\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1. Expérimentation : algorithme optimisation Adam avec différents batch size <a class= \"anchor\" id=\"section_4_4_1\"></a>\n",
    "Description de l'expérimentation :\n",
    "* nombre de couches cachées: **1**\n",
    "* nombre de cellule: **784**\n",
    "* batch size: **32**\n",
    "* optimizer: **Adam**\n",
    "* learning rate: **0.001**\n",
    "* epochs: **30**\n",
    "* process image method: **None**\n",
    "* activation function: **relu**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_sizes = [32, 86, 200, 450]\n",
    "plt.figure(figsize=(10, 8)).subplots_adjust(hspace=2, wspace=0.4)\n",
    "\n",
    "for i in range(len(batch_sizes)):\n",
    "    model, model_fit, score = mlp_model(train_set=train,\n",
    "                                        test_set=test,\n",
    "                                        validate_set=validate,\n",
    "                                        optimizer_name=\"adam\",\n",
    "                                        nb_hidden_layer=1,\n",
    "                                        nb_cellules=784,\n",
    "                                        batch_size=batch_sizes[i],\n",
    "                                        learning_rate=0.001,\n",
    "                                        epochs=30,\n",
    "                                        activation_function=\"relu\",\n",
    "                                        do_data_augmentation=True)\n",
    "    plot_no = 420 + (i + 1)\n",
    "    plt.subplot(plot_no)\n",
    "\n",
    "    plt.plot(model_fit.history['accuracy'], label='train')\n",
    "    plt.plot(model_fit.history['val_accuracy'], label='validate')\n",
    "    plt.title('batch=' + str(batch_sizes[i]), pad=-40)\n",
    "\n",
    "    all_scores[\"model_data_aug\" + str(batch_sizes[i])] = score\n",
    "    all_models[\"model_data_aug\" + str(batch_sizes[i])] = model\n",
    "    all_models_fit[\"model_data_aug\" + str(batch_sizes[i])] = model_fit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous avons également un faible signe de sur-apprentissage avec ce pré-traitement des données quelque soit le batch. Mais le taux de réussite est le plus haut que nous ayons pu avoir."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Avec seuillage <a class= \"anchor\" id=\"section_4_3\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train, test, validate = data_preparation(train_org, test_org, validate_org, process_img=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_img(train[0], train[1].values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.1. Expérimentation : algorithme optimisation Adam avec différents batch size <a class= \"anchor\" id=\"section_4_3_1\"></a>\n",
    "Description de l'expérimentation :\n",
    "* nombre de couches cachées: **3**\n",
    "* nombre de cellule: **128**\n",
    "* batch size: **32**\n",
    "* optimizer: **Adam**\n",
    "* learning rate: **0.001**\n",
    "* epochs: **30**\n",
    "* process image method: **[binary threshold](https://docs.opencv.org/3.4.0/d7/d4d/tutorial_py_thresholding.html)**\n",
    "* activation function: **relu**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_sizes = [32, 86, 200, 450]\n",
    "plt.figure(figsize=(10, 8)).subplots_adjust(hspace=2, wspace=0.4)\n",
    "\n",
    "for i in range(len(batch_sizes)):\n",
    "    model, model_fit, score = mlp_model(train_set=train,\n",
    "                                        test_set=test,\n",
    "                                        validate_set=validate,\n",
    "                                        optimizer_name=\"adam\",\n",
    "                                        nb_hidden_layer=3,\n",
    "                                        nb_cellules=128,\n",
    "                                        batch_size=batch_sizes[i],\n",
    "                                        learning_rate=0.001,\n",
    "                                        epochs=30,\n",
    "                                        activation_function=\"relu\")\n",
    "    plot_no = 420 + (i + 1)\n",
    "    plt.subplot(plot_no)\n",
    "\n",
    "    plt.plot(model_fit.history['accuracy'], label='train')\n",
    "    plt.plot(model_fit.history['val_accuracy'], label='validate')\n",
    "    plt.title('batch=' + str(batch_sizes[i]), pad=-40)\n",
    "\n",
    "    all_scores[\"model_imgprc\" + str(batch_sizes[i])] = score\n",
    "    all_models[\"model_imgprc\" + str(batch_sizes[i])] = model\n",
    "    all_models_fit[\"model_imgprc\" + str(batch_sizes[i])] = model_fit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On remarque qu'avec le seuillage que nous avons appliqué (de 0.5), il y a des risques de sur-apprentissage lorsque la taille du batch est petite."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Avec standardisation des données <a class= \"anchor\" id=\"section_4_5\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train, test, validate = data_preparation(train_org, test_org, validate_org, process_img=False, standard_application=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_img(train[0], train[1].values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5.1. Expérimentation : algorithme optimisation Adam, 3 couches cachées avec différents batch size <a class= \"anchor\" id=\"section_4_5_1\"></a>\n",
    "Description de l'expérimentation\n",
    "* nombre de couches cachées : **3**\n",
    "* nombre de cellule: **128**\n",
    "* batch size: **[32, 86, 200, 450]**\n",
    "* optimizer: **Adam**\n",
    "* learning rate: **0.001**\n",
    "* epochs: **30**\n",
    "* process image method: **None**\n",
    "* activation function: **sigmoid**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_sizes = [32, 86, 200, 450]\n",
    "plt.figure(figsize=(10, 8)).subplots_adjust(hspace=2, wspace=0.4)\n",
    "\n",
    "for i in range(len(batch_sizes)):\n",
    "    model, model_fit, score = mlp_model(train_set=train,\n",
    "                                        test_set=test,\n",
    "                                        validate_set=validate,\n",
    "                                        optimizer_name=\"adam\",\n",
    "                                        nb_hidden_layer=3,\n",
    "                                        nb_cellules=128,\n",
    "                                        batch_size=batch_sizes[i],\n",
    "                                        learning_rate=0.001,\n",
    "                                        epochs=30,\n",
    "                                        activation_function=\"sigmoid\")\n",
    "    plot_no = 420 + (i + 1)\n",
    "    plt.subplot(plot_no)\n",
    "\n",
    "    plt.plot(model_fit.history['accuracy'], label='train')\n",
    "    plt.plot(model_fit.history['val_accuracy'], label='validate')\n",
    "    plt.title('batch=' + str(batch_sizes[i]), pad=-40)\n",
    "\n",
    "    all_scores[\"model_norm_\" + str(batch_sizes[i])] = score\n",
    "    all_models[\"model_norm_\" + str(batch_sizes[i])] = model\n",
    "    all_models_fit[\"model_norm_\" + str(batch_sizes[i])] = model_fit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lorsque nous standardisons les données, nous avons à peu près la même interprétation des graphiques que lorsque nous ne le faisons pas (voir 2.2)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Meilleur modèle <a class= \"anchor\" id=\"section_4_6\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6.1. Comparaison taux de réussite <a class= \"anchor\" id=\"section_4_6_1\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss = [z[0] for z in all_scores.values()]\n",
    "acc = [z[1] for z in all_scores.values()]\n",
    "models = list(all_scores.keys())\n",
    "scores_df = pd.DataFrame({'Model': models, 'Accuracy': acc, 'Loss': loss})\n",
    "scores_df = scores_df.sort_values(by=['Accuracy'], ascending=True)\n",
    "ax = scores_df[-10:].plot.barh(x='Model', y='Accuracy')\n",
    "ax.set_xscale(\"log\")\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax2 = scores_df[-10:].plot.barh(x='Model', y='Loss')\n",
    "ax2.set_xscale(\"log\")\n",
    "ax2.bar_label(ax2.containers[0])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6.2. Meilleur modèle <a class= \"anchor\" id=\"section_4_6_2\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores_df = scores_df.sort_values(by=['Accuracy'], ascending=False)\n",
    "model_name = scores_df.iloc[0][\"Model\"]\n",
    "model = all_models[model_name]\n",
    "model_fit = all_models_fit[model_name]\n",
    "print(\"Le meilleur modèle est : \", model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_model_result(model_fit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous constatons un léger sur-apprentissage avec ce modèle."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_pred, Y_test = plot_confusion_matrix(model, test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous observons que la majorité des erreurs proviennent du 4. En effet, tous les chiffres sont souvent prédits comme étant le 4 (prédit un 8 243 fois alors que c'est un 4). Et celui-ci n'a jamais été prédit pour une autre valeur que lui-même.\n",
    "\n",
    "De plus, même si le taux de réussite est le plus fort, nous remarquons qu'il y a de nombreuses erreurs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_errors(Y_pred, test[1], test[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comme dit juste avant, le 4 est souvent prédit à tort. Il est difficile de comprendre réellement pourquoi lorsque nous regardons les images mal prédites.\n",
    "\n",
    "Cependant, cette erreur de prédiction pour le chiffre 4 est sûrement dû à notre pré-traitement des images. Notre degré de pivot de l'image et l'agrandissemebt de celle-ci amènent à une reconnaissance (souvent à tord) du chiffre 4."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6.2.1. Meilleur modèle sans sur-apprentissage <a class= \"anchor\" id=\"section_4_6_2_1\"></a>\n",
    "\n",
    "Nous allons présenter le premier meilleur modèle qui ne montre aucun signe de sur-apprentissage."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = scores_df.iloc[9][\"Model\"]\n",
    "model = all_models[model_name]\n",
    "model_fit = all_models_fit[model_name]\n",
    "print(\"Le meilleure modèle sans signe de sur-apprentissage : \", model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_model_result(model_fit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_pred, Y_test = plot_confusion_matrix(model, test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_errors(Y_pred, test[1], test[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Contrairement à l'autre modèle, il n'a pas ce problème de prédire majoritairement le chiffre 4, ce qui confirme notre hypothèse concernant notre transformation des données qui prédit partout le chiffre 4.\n",
    "\n",
    "Nous constatons tout de même que le chiffre 4 est une nouvelle fois prédit à tord, le plus souvent. Notamment, il y a un problème de différenciation entre le chiffre 4 et 9.\n",
    "\n",
    "De plus, il y a souvent une mauvaise prédiction donnée pour le chiffre 1. La plupart du temps, le modèle prédit un 1 mais aussi un 2, un 3 ou un 8."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## V. Conclusion <a class= \"anchor\" id=\"chapter5\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous obtenons un très bon taux de précision lorsque nous effectuons un pré-traitement des données.\n",
    "\n",
    "Cependant, on remarque qu'il y a souvent des mauvaises prédictions pour le chiffre 4 et 1. Pour améliorer encore plus nos modèles, il faudrait faire un pré-traitement des données qui faciliterai la compréhension de ces deux chiffres, sans pour autant changer l'analyse des autres chiffres."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}